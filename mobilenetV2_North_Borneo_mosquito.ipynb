{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO2qU6JXGmfbrt88sQ7OxH+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songguan26/Deep-learning-models-to-automatically-classify-medically-important-mosquitoes-in-North-Borneo/blob/main/mobilenetV2_North_Borneo_mosquito.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9ky8S38uqb2",
        "outputId": "cd2afd11-04c2-4910-f8ab-c7d36696a422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras import Model, layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, Input, Conv2D, MaxPooling2D, Flatten,MaxPooling3D"
      ],
      "metadata": {
        "id": "4sA8TrcKvv-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "maJEKtmQvv7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = 'path to images'\n",
        "train_pred_test_folders = os.listdir(root_path)\n",
        "\n",
        "seg_train_folders = 'train'\n",
        "seg_test_folders = 'test'\n",
        "seg_pred_folders = 'pred'"
      ],
      "metadata": {
        "id": "y-zhgVL-vv4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_history_stuff(history, history_file_name, ismobilenet=False):\n",
        "    save_history(history, history_file_name)\n",
        "    plot_accuracy_from_history(history, ismobilenet)\n",
        "    plot_loss_from_history(history)\n",
        "\n",
        "def save_history(history, model_name):\n",
        "    #convert the history.history dict to a pandas DataFrame:\n",
        "    hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "    # save to json:\n",
        "    hist_json_file = model_name+'_history.json'\n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "    # or save to csv:\n",
        "    hist_csv_file = model_name+'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "\n",
        "def plot_accuracy_from_history(history, ismobilenet=False):\n",
        "    color = sns.color_palette()\n",
        "    if(ismobilenet == False):\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "    else:\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.lineplot(x=epochs, y=acc, label='Training Accuracy')\n",
        "    sns.lineplot(x=epochs, y=val_acc,label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss_from_history(history):\n",
        "    color = sns.color_palette()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(loss))\n",
        "\n",
        "    sns.lineplot(x=epochs, y=loss,label='Training Loss')\n",
        "    sns.lineplot(x=epochs, y=val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vvyl9Uofvv1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator( rescale = 1.0/255.,shear_range=0.2,zoom_range=0.0)\n",
        "\n",
        "# we are rescaling by 1.0/255 to normalize the rgb values if they are in range 0-255 the values are too high for good model performance.\n",
        "train_generator = train_datagen.flow_from_directory(seg_train_folders,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(224, 224))\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.) #we are only normalising to make the prediction, the other parameters were used for agumentation and train weights\n",
        "validation_generator = validation_datagen.flow_from_directory(seg_test_folders, shuffle=True, batch_size=32, class_mode='categorical', target_size=(224, 224))\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "test_generator = test_datagen.flow_from_directory(seg_pred_folders, shuffle=True, batch_size=32, class_mode='categorical', target_size=(224, 224))"
      ],
      "metadata": {
        "id": "BfY94Qkevvy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_map_classes = {v: k for k, v in validation_generator.class_indices.items()}\n",
        "print(validation_generator.class_indices)\n",
        "print(inv_map_classes)"
      ],
      "metadata": {
        "id": "jS0DgjG1vvwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#strategy one ->adamlr0.001\n",
        "#freezing convolutional layers; replacing classification layers\n",
        "MobileNetV2_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "for layers in MobileNetV2_model.layers:\n",
        "            layers.trainable=False\n",
        "\n",
        "last_output = MobileNetV2_model.layers[-1].output\n",
        "MobileNetV2_x = Flatten()(last_output)\n",
        "MobileNetV2_x = Dense(128, activation = 'relu')(MobileNetV2_x)\n",
        "MobileNetV2_x = Dropout(0.3)(MobileNetV2_x)\n",
        "MobileNetV2_x = Dense(2, activation = 'softmax')(MobileNetV2_x)\n",
        "MobileNetV2_final_model = Model(MobileNetV2_model.input, MobileNetV2_x)\n",
        "MobileNetV2_final_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# MobileNetV2\n",
        "MobileNetV2_filepath = 'MobileNetV2'+'-saved-model-{epoch:02d}-loss-{loss:.2f}.hdf5'\n",
        "MobileNetV2_checkpoint = tf.keras.callbacks.ModelCheckpoint(MobileNetV2_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "MobileNetV2_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "MobileNetV2_history = MobileNetV2_final_model.fit(train_generator, epochs = 100, batch_size=32, validation_data = validation_generator,callbacks=[MobileNetV2_checkpoint,MobileNetV2_early_stopping],verbose=1)\n",
        "\n",
        "do_history_stuff(MobileNetV2_history, 'MobileNetV2_model')"
      ],
      "metadata": {
        "id": "relYXDcgvvtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "\n",
        "MobileNetV2_best_model = MobileNetV2_final_model\n",
        "\n",
        "def mode(my_list):\n",
        "    ct = Counter(my_list)\n",
        "    max_value = max(ct.values())\n",
        "    return ([key for key, value in ct.items() if value == max_value])\n",
        "\n",
        "true_value = []\n",
        "combined_model_pred = []\n",
        "MobileNetV2_pred = []\n",
        "for folder in os.listdir(seg_pred_folders):\n",
        "\n",
        "    test_image_ids = os.listdir(os.path.join(seg_pred_folders,folder))\n",
        "\n",
        "    for image_id in test_image_ids[:int(len(test_image_ids))]:\n",
        "\n",
        "        path = os.path.join(seg_pred_folders,folder,image_id)\n",
        "\n",
        "        true_value.append(validation_generator.class_indices[folder])\n",
        "        img = cv2.resize(cv2.imread(path),(224,224))\n",
        "        img_normalized = img/255\n",
        "\n",
        "        #MobileNetV2\n",
        "        MobileNetV2_image_prediction = np.argmax(MobileNetV2_best_model.predict(np.array([img_normalized])))\n",
        "        MobileNetV2_pred.append(MobileNetV2_image_prediction)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#from mlxtend.plotting import plot_confusion_matrix\n",
        "def clf_report(true_value, model_pred):\n",
        "\n",
        "    classes = validation_generator.class_indices.keys()\n",
        "    TP_count = [true_value[i] == model_pred[i] for i in range(len(true_value))]\n",
        "    model_accuracy = np.sum(TP_count)/len(TP_count)\n",
        "    print('Model Accuracy', model_accuracy)\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    cm = confusion_matrix(true_value,model_pred)\n",
        "    plt.imshow(cm,interpolation='nearest',cmap=plt.cm.viridis)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    thresh = cm.max()*0.8\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,cm[i,j],\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"black\" if cm[i,j] > thresh else \"white\")\n",
        "        pass\n",
        "\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    pass\n",
        "\n",
        "    print(classification_report(true_value, model_pred, target_names = list(classes)))\n",
        "\n",
        "# MobileNetV2 model classification report\n",
        "clf_report(true_value, MobileNetV2_pred)"
      ],
      "metadata": {
        "id": "O_nxNDr_vvq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}